# Industrial Wireless Communication with Graph Neural Networks  

It is strongly recommended to use **Python 3.10** due to DGL compatibility issues.

Create and activate a virtual environment:

```bash
python3.10 -m venv gnn_env
source gnn_env/bin/activate
```

## 1. Install dependencies:
```bash
pip install -r requirements.txt
```

## 2. Generate the Dataset
Synthetic datasets are generated by simulating an industrial wireless scenario with multiple Access Points (APs), wireless nodes, and an OFDM physical layer.

```bash
python data_generation.py
```

## 3. Model Training
A GNN-based scheduler is trained to learn scheduling and AP-assignment policies from Channel State Information (CSI) and network topology.

```bash
python training.py
```

## 4. Model Testing
The trained model is evaluated on unseen scenarios. Predictions are mapped to valid OFDMA frame structures and analyzed through multiple performance metrics.

```bash
python testing.py
```

## 5. Visualize different strategies comparison
Different resource allocation strategies are compared in terms of throughput and resource utilization, and their corresponding time–frequency grids are visualized.

```bash
python benchmarking.py
```

## Overview

This project investigates resource allocation strategies for industrial wireless communication systems using Graph Neural Networks (GNNs).

The considered scenario consists of multiple Access Points (APs) and multiple wireless nodes operating over an OFDM physical layer. The system is modeled in terms of time slots and frequency subcarriers, with Channel State Information (CSI) available at the scheduler.

The proposed GNN-based approach learns a scheduling and AP-assignment policy from data and is then used to generate a valid OFDMA frame structure, i.e., a time–frequency resource grid, under realistic MAC constraints:
- one node per AP per time slot,
- no duplicate node assignments within the same time slot,
- fixed and contiguous subcarrier partitions per AP.

The output of the GNN is therefore not limited to abstract scheduling decisions, but is explicitly mapped to an OFDMA resource grid, enabling a direct comparison with classical multiple access schemes.

## Resource Allocation Strategies

The following resource allocation schemes are implemented and compared:

- **GNN-based OFDMA**:  
  A learned scheduling policy that selects, for each AP and time slot, the node to be served. The decision is mapped to an OFDMA frame by assigning the AP-specific subcarrier block to the selected node.

- **TDMA (Time Division Multiple Access)**:  
  A baseline scheme where a single node occupies the entire bandwidth in a given time slot.

- **FDMA (Frequency Division Multiple Access)**:  
  A static frequency-based allocation where subcarriers are permanently assigned without temporal adaptation.

- **Optimal Allocation**:  
  An offline upper-bound solution that maximizes the system throughput under the same resource constraints. This solution is not intended for real-time implementation and serves only as a performance benchmark.

## Performance Evaluation

Performance is evaluated both quantitatively and qualitatively:

- System throughput (bits per frame),
- Scheduling and AP-assignment accuracy,
- Transmission completion rate,
- Visual inspection of time–frequency resource grids.

The use of explicit OFDMA frames allows a fair and structured comparison between learning-based and classical allocation strategies, following the methodology commonly adopted in industrial wireless communication literature.



